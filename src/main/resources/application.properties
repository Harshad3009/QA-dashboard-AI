spring.application.name=QA dashboard AI
server.port=8080

# Gemini Configuration
# We use "gemini-1.5-flash" for speed/cost or "gemini-1.5-pro" for complex reasoning.
langchain4j.google-ai-gemini.chat-model.model-name=gemini-1.5-flash
langchain4j.google-ai-gemini.chat-model.api-key=${GEMINI_API_KEY}

# Logging (So we can see the magic happening)
langchain4j.google-ai-gemini.chat-model.log-requests=true
langchain4j.google-ai-gemini.chat-model.log-responses=true
